{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjYMmu_PEYVt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, roc_auc_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgLoQAUCETms"
      },
      "outputs": [],
      "source": [
        "# #PHISHING WEBSITES\n",
        "# url = 'https://archive.ics.uci.edu/static/public/967/data.csv'\n",
        "\n",
        "# response = requests.get(url)\n",
        "\n",
        "# if response.status_code == 200:\n",
        "#     data = pd.read_csv(io.StringIO(response.text))\n",
        "#     save_path = 'data.csv'\n",
        "#     data.to_csv(save_path, index=False)\n",
        "# else:\n",
        "#     print(f\"Error downloading CSV: {response.status_code}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def split_csv(input_file, output_dir, chunk_size):\n",
        "#     if not os.path.exists(output_dir):\n",
        "#         os.makedirs(output_dir)\n",
        "\n",
        "#     with open(input_file, 'r', newline='', encoding='utf-8') as csvfile:\n",
        "#         reader = csv.reader(csvfile)\n",
        "#         header = next(reader) \n",
        "\n",
        "#         file_count = 1\n",
        "#         current_chunk = 0\n",
        "#         output_file = os.path.join(output_dir, f'data_{file_count}.csv')\n",
        "\n",
        "#         for row in reader:\n",
        "#             if current_chunk == 0:\n",
        "#                 with open(output_file, 'w', newline='', encoding='utf-8') as out_csvfile:\n",
        "#                     writer = csv.writer(out_csvfile)\n",
        "#                     writer.writerow(header) \n",
        "\n",
        "#             with open(output_file, 'a', newline='', encoding='utf-8') as out_csvfile:\n",
        "#                 writer = csv.writer(out_csvfile)\n",
        "#                 writer.writerow(row)\n",
        "\n",
        "#             current_chunk += 1\n",
        "#             if current_chunk == chunk_size:\n",
        "#                 current_chunk = 0\n",
        "#                 file_count += 1\n",
        "#                 output_file = os.path.join(output_dir, f'output_{file_count}.csv')\n",
        "\n",
        "# input_file = 'dataset.csv'\n",
        "# output_dir = 'datasets'\n",
        "# chunk_size = 10000\n",
        "\n",
        "# split_csv(input_file, output_dir, chunk_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "directory = 'datasets'\n",
        "\n",
        "dfs = []\n",
        "count = 0\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "    df = pd.read_csv(os.path.join(directory, filename))\n",
        "    dfs.append(df)\n",
        "    count += 1\n",
        "\n",
        "df = pd.concat(dfs, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "ipgbownXHDIe",
        "outputId": "59d09567-ed86-4c6b-d761-2ad495fbd44f"
      },
      "outputs": [],
      "source": [
        "def analyze_and_visualize_label_distribution(df):\n",
        "    print(df['label'].value_counts())\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    df['label'].value_counts().plot(kind='bar', color='skyblue')\n",
        "    plt.title('Label Distribution')\n",
        "    plt.xlabel('Label')\n",
        "    plt.ylabel('Count')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(axis='y', linestyle=':', alpha=0.7)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "analyze_and_visualize_label_distribution(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9qB3brcIV5N"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TALsPa2IWOy"
      },
      "outputs": [],
      "source": [
        "df['label'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t93iLLdVI_pV"
      },
      "outputs": [],
      "source": [
        "def data_cleaning(df):\n",
        "    df.columns = df.columns.str.strip()\n",
        "    print(\"Dataset Shape: \", df.shape)\n",
        "    num = df._get_numeric_data()\n",
        "    num[num < 0] = 0\n",
        "data_cleaning(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# label_encoder = LabelEncoder()\n",
        "# label_encoded_cols = []\n",
        "\n",
        "# for col in df.columns:\n",
        "#     if df[col].dtype == 'object':\n",
        "#         df[col] = label_encoder.fit_transform(df[col])\n",
        "#         label_encoded_cols.append(col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data subsampling and separating features and target variables\n",
        "subsample_df=df.groupby('label').apply(pd.DataFrame.sample,frac=0.1).reset_index(drop=True)\n",
        "x=subsample_df.drop(['label'],axis=1)\n",
        "y=subsample_df['label']\n",
        "# reducing the dimensionality into 2\n",
        "pca=PCA(n_components=2, random_state=0)\n",
        "z=pca.fit_transform(x)\n",
        "# combining the principal components and labels into a DataFrame\n",
        "pca_df=pd.DataFrame()\n",
        "pca_df['label']=y\n",
        "pca_df['PCA 1']=z[:,0]\n",
        "pca_df['PCA 2']=z[:,1]\n",
        "# visualizes the data in the reduced two-dimensional space\n",
        "# which allows to explore potential patterns and relationships between the features and their labels\n",
        "sns.scatterplot(data=pca_df,x='PCA 1',y='PCA 2',hue='label',palette=sns.color_palette('hls',len(pca_df.label.value_counts()))).set_title(\"PCA Projection\")\n",
        "\n",
        "plt.legend(loc='center left',bbox_to_anchor=(1,0.5))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_df=df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# creating a data frame with balanced data\n",
        "size=len(df.loc[df.label==0])\n",
        "print(size)\n",
        "bal_df=df.groupby('label').apply(lambda x: x.sample(n=min(size,len(x))))\n",
        "sns.countplot(data=bal_df,x='label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# feature scaling and label conversion to int\n",
        "# applying normalization since we have label encoding\n",
        "X=bal_df.drop(columns='label')\n",
        "y=bal_df['label'].astype('int')\n",
        "X=MinMaxScaler().fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
        "print(X_train.shape,\" \",X_test.shape)\n",
        "print(y_train.shape,\" \",y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Xn=new_df.drop(columns='label')\n",
        "Xn=MinMaxScaler().fit_transform(Xn)\n",
        "yn=new_df['label']\n",
        "yn=LabelEncoder().fit_transform(yn)\n",
        "Xn_train,Xn_test,yn_train,yn_test=train_test_split(Xn,yn,test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(Xn_test.shape,Xn_train.shape)\n",
        "print(yn_test.shape,yn_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_and_evaluate_cnn(X_train, y_train, X_test, y_test):\n",
        "    # Reshape data for CNN\n",
        "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "    # Build CNN model\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(50, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Define callbacks\n",
        "    callbacks = [\n",
        "        ModelCheckpoint('best_model.keras', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1),\n",
        "        EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1),\n",
        "    ]\n",
        "\n",
        "    # Train the model with callbacks\n",
        "    history = model.fit(\n",
        "        X_train, y_train, \n",
        "        epochs=20, \n",
        "        batch_size=128, \n",
        "        validation_data=(X_test, y_test),\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    # Plot training history\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "    # Plot training & validation loss values\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Evaluate the model\n",
        "    loss, accuracy = model.evaluate(X_test, y_test)\n",
        "    print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')\n",
        "\n",
        "    # Confusion Matrix\n",
        "    y_pred_proba = model.predict(X_test)\n",
        "    y_pred = (y_pred_proba > 0.5).astype(int)  \n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['0', '1'])\n",
        "    disp.plot(cmap='Blues', values_format='d')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "    # Plot ROC Curve\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "best_model = train_and_evaluate_cnn(X_train, y_train, X_test, y_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
